{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of quantizer/tokenizer for trajectories from MotionLM paper\n",
    "## https://arxiv.org/abs/2309.16534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TrajectoryQuantizer:\n",
    "    def __init__(self, num_bins=128, delta_min=-18, delta_max=18, verlet_bins=128):\n",
    "        self.num_bins = num_bins\n",
    "        self.delta_min = delta_min\n",
    "        self.delta_max = delta_max\n",
    "        self.verlet_bins = verlet_bins # using 128 uses the default bin assumptions of num_bins\n",
    "        self.bin_width = (delta_max - delta_min) / num_bins\n",
    "        self.cartesian_mapping = self.create_cartesian_product_mapping()\n",
    "\n",
    "    def normalize_trajectory(self, trajectory, initial_position, initial_heading):\n",
    "        # Translate the trajectory so that the initial position is at the origin\n",
    "        normalized_trajectory = trajectory - initial_position\n",
    "\n",
    "        # Create a rotation matrix to align the initial heading with the x-axis\n",
    "        cos_theta, sin_theta = torch.cos(initial_heading), torch.sin(initial_heading)\n",
    "        rotation_matrix = torch.tensor([[cos_theta, -sin_theta], [sin_theta, cos_theta]])\n",
    "\n",
    "        # Apply the rotation to all points in the trajectory\n",
    "        normalized_trajectory = torch.matmul(normalized_trajectory, rotation_matrix.T)\n",
    "\n",
    "        return normalized_trajectory\n",
    "\n",
    "    def compute_delta_actions(self, normalized_traj):\n",
    "        # Compute deltas follow LaneGCN type of displacements\n",
    "        deltas = normalized_traj[1:] - normalized_traj[:-1]\n",
    "        # print(f\"Normalized traj: {normalized_traj}\")\n",
    "        # print(f\"deltas: {deltas}\")\n",
    "\n",
    "        # Quantize deltas\n",
    "        delta_x_bins = torch.floor((deltas[:, 0] - self.delta_min) / self.bin_width).long()\n",
    "        delta_y_bins = torch.floor((deltas[:, 1] - self.delta_min) / self.bin_width).long()\n",
    "        \n",
    "        # Clip values to ensure they fall within the valid bin range\n",
    "        delta_x_bins = torch.clamp(delta_x_bins, 0, self.num_bins - 1)\n",
    "        delta_y_bins = torch.clamp(delta_y_bins, 0, self.num_bins - 1)\n",
    "\n",
    "        return delta_x_bins, delta_y_bins\n",
    "\n",
    "    def apply_verlet_wrapper(self, delta_bins):\n",
    "        # TODO: add the verlet integration to reduce the bin size from 128 to 13(as mentioned in the paper)\n",
    "        return delta_bins\n",
    "\n",
    "    def create_cartesian_product_mapping(self):\n",
    "        # Generate all possible combinations of bin indices\n",
    "        cartesian_product = list(product(range(self.verlet_bins), repeat=2))\n",
    "        # Create a mapping from tuple (x_bin, y_bin) to a unique index\n",
    "        return {bin_indices: i for i, bin_indices in enumerate(cartesian_product)}\n",
    "\n",
    "    def map_to_single_index(self, delta_x_bins, delta_y_bins):\n",
    "        indices = [self.cartesian_mapping[(x.item(), y.item())] for x, y in zip(delta_x_bins, delta_y_bins)]\n",
    "        return torch.tensor(indices)\n",
    "\n",
    "    def quantize_trajectory(self, trajectory, initial_position, initial_heading):\n",
    "        normalized_traj = self.normalize_trajectory(trajectory, initial_position, initial_heading)\n",
    "        delta_x_bins, delta_y_bins = self.compute_delta_actions(normalized_traj)\n",
    "        verlet_x_bins = self.apply_verlet_wrapper(delta_x_bins)\n",
    "        verlet_y_bins = self.apply_verlet_wrapper(delta_y_bins)\n",
    "        single_indices = self.map_to_single_index(verlet_x_bins, verlet_y_bins)\n",
    "        # print(f\"Normalized trajectories: {normalized_traj}\")\n",
    "        plt.plot(normalized_traj) # to see the normalized trajectory\n",
    "    \n",
    "        return single_indices\n",
    "\n",
    "## Uncomment the following if you want to use a toy example where the sampling is done from cos and sine curves.\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Create a sample trajectory\n",
    "#     trajectory_length = 8*2 # 2Hz at 8s \n",
    "#     sample_pt = np.linspace(-1, np.pi, trajectory_length).astype(np.float32)\n",
    "#     delta_x = torch.tensor(np.sin(sample_pt))\n",
    "#     delta_y = torch.tensor(np.cos(sample_pt))\n",
    "    \n",
    "#     initial_position = torch.tensor([delta_x[0], delta_y[0]])\n",
    "#     initial_heading = torch.tensor(0.0)  # Assuming initial heading is along x-axis\n",
    "#     quantizer = TrajectoryQuantizer()\n",
    "#     quantized_trajectory = quantizer.quantize_trajectory(torch.stack([delta_x, delta_y], dim=1), initial_position, initial_heading)\n",
    "#     plt.plot(delta_x, delta_y, 'o' )\n",
    "    \n",
    "#     print(f\"Quantized trajectory indices: \\n {quantized_trajectory}\")\n",
    "#     print(f\"Vocabulary size: {len(quantizer.cartesian_mapping)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader for ArgoVerse2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import matplotlib.pyplot as plt\n",
    "from av2.datasets.motion_forecasting.data_schema import ObjectType\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "# relative imports\n",
    "from av2.map.map_api import ArgoverseStaticMap\n",
    "from av2.datasets.motion_forecasting import scenario_serialization\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from av2.datasets.motion_forecasting.data_schema import (\n",
    "    ArgoverseScenario,\n",
    "    ObjectType,\n",
    "    TrackCategory,\n",
    "    ObjectState\n",
    ")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def get_common_ax_plots():\n",
    "    fig = plt.figure(1, figsize=(10, 10), dpi=300)\n",
    "    ax = fig.add_subplot(111)\n",
    "    return fig, ax\n",
    "\n",
    "@dataclass\n",
    "class Av2Configs:\n",
    "    data_root_dir: str = \"data/2_av2/\"\n",
    "    deterministic_loading: bool = True\n",
    "\n",
    "def get_ft_obs(scenario: ArgoverseScenario):\n",
    "    \"\"\"\n",
    "    Returns the past and fut obs for a focal track given a scenario\n",
    "    :param scenario:\n",
    "    :return: track, obs_past, obs_fut, heading_angle\n",
    "    \"\"\"\n",
    "    for track in scenario.tracks:\n",
    "        if track.category == TrackCategory.FOCAL_TRACK:  # and track.object_type == ObjectType.VEHICLE:\n",
    "            # get the last observed position of the focal track\n",
    "            observed_states_past = [obj_states.position for obj_states in track.object_states if\n",
    "                                    obj_states.observed]\n",
    "            # print(f\"Last observed position of the Focal track: {observed_states[-1]}\")\n",
    "            observed_states_future = [obj_states.position for obj_states in track.object_states if\n",
    "                                      not obj_states.observed]\n",
    "            \n",
    "            heading_angle = [obj_states.heading for obj_states in track.object_states]\n",
    "            \n",
    "\n",
    "            return track, observed_states_past, observed_states_future, heading_angle\n",
    "\n",
    "def custom_collate(batch):\n",
    "    # Assuming all dictionaries in the batch have the same keys\n",
    "    return {key: [d[key] for d in batch] for key in batch[0].keys()}\n",
    "\n",
    "class DataProcessorAV2(Dataset):\n",
    "    def __init__(self, config: Av2Configs, args, split):\n",
    "        self.data_root_dir = Path(config.data_root_dir) / split  # for the dataset\n",
    "        self.config = config\n",
    "        self.args = args\n",
    "        self.file_names = os.listdir(self.data_root_dir)\n",
    "        self.total_trajectories = []\n",
    "        if not config.deterministic_loading:\n",
    "            random.shuffle(self.file_names)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        log_map_path = Path(self.data_root_dir) / file_name\n",
    "        scenario_path = Path(self.data_root_dir) / file_name / f\"scenario_{file_name}.parquet\"\n",
    "\n",
    "        if not log_map_path.exists():\n",
    "            raise FileNotFoundError(f\"The map directory {log_map_path} does not exist.\")\n",
    "\n",
    "        scenario = scenario_serialization.load_argoverse_scenario_parquet(scenario_path)\n",
    "        avm = ArgoverseStaticMap.from_map_dir(log_map_path, build_raster=False)\n",
    "        # fig, ax = get_common_ax_plots()\n",
    "        track, ft_obs_past, ft_obs_future, ft_heading_angle = get_ft_obs(scenario)\n",
    "        required_obj = [ObjectType.VEHICLE]\n",
    "        \n",
    "        data = {\n",
    "        \"track\": None,\n",
    "        \"ft_obs_past\": None,\n",
    "        \"ft_obs_future\": None,\n",
    "        \"ft_heading_angle\": None,\n",
    "        \"is_valid\": False\n",
    "        }\n",
    "\n",
    "        for obj in required_obj:\n",
    "            if track.object_type == obj:\n",
    "                data[\"track\"] = track\n",
    "                data[\"ft_obs_past\"] = ft_obs_past\n",
    "                data[\"ft_obs_future\"] = ft_obs_future\n",
    "                data[\"ft_heading_angle\"] = ft_heading_angle\n",
    "                data[\"is_valid\"] = True\n",
    "        \n",
    "        return data\n",
    "\n",
    "\n",
    "av_processor = DataProcessorAV2(Av2Configs(), args=None, split=\"train\")\n",
    "loader = DataLoader(av_processor, batch_size=1, shuffle=False, collate_fn=custom_collate)\n",
    "\n",
    "import sys\n",
    "for i, data in enumerate(loader):\n",
    "    if True in data[\"is_valid\"]:\n",
    "        # Build the full trajectory = ft_obs_past + ft_obs_future\n",
    "        full_trajectory = np.concatenate(data[\"ft_obs_past\"] + data[\"ft_obs_future\"])\n",
    "        # init the pos, heading_angle whereby we are normalizing the rest of the waypoints in the\n",
    "        # trajectories to the first (xy) coordinate. \n",
    "        initial_position = full_trajectory[0]\n",
    "        heading_angles = np.concatenate(data[\"ft_heading_angle\"])\n",
    "        initial_heading = heading_angles[0]\n",
    "        # print(f\"Full trajectory: {full_trajectory.dtype} \\n Initial Position: {initial_position.dtype} Initial Heading: {initial_heading.dtype}\")\n",
    "        quantizer = TrajectoryQuantizer()\n",
    "        quantized_trajectory = quantizer.quantize_trajectory(torch.tensor(full_trajectory.astype(np.float32)), \n",
    "                                                             torch.tensor(initial_position.astype(np.float32)),\n",
    "                                                             torch.tensor(initial_heading.astype(np.float32))\n",
    "                                                            )\n",
    "        \n",
    "        # print(f\"Full trajectory\")\n",
    "        print(f\"Quantized trajectory indices: \\n {quantized_trajectory}\")\n",
    "        print(f\"Vocabulary size: {len(quantizer.cartesian_mapping)}\")\n",
    "        \n",
    "    if i>=10:\n",
    "        sys.exit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_unnamed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
